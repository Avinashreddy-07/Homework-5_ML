ðŸ“˜ README â€” Scaled Dot-Product Attention & Simple Transformer Encoder Block

This README explains the code for:

Scaled Dot-Product Attention (NumPy)

Simple Transformer Encoder Block (PyTorch)

Each section includes:

What the component does

How the code works (line-by-line logic)

Expected outputs and shapes
